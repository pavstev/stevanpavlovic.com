---
title: "Caching Strategies in Distributed Systems"
description: "Implement effective caching patterns to improve performance and reduce load"
pubDate: "2024-02-25"
tags:
  - id: caching
    label: Caching
  - id: redis
    label: Redis
  - id: performance
    label: Performance
  - id: distributed-systems
    label: Distributed Systems
image: "../../assets/laptop-desk.jpg"
---

Caching is crucial for scalable applications. Understanding when and how to cache can dramatically improve performance.

## Cache-Aside Pattern

The application manages the cache:

```typescript
class UserService {
  async getUser(id: string): Promise<User> {
    // Try cache first
    const cached = await redis.get(`user:${id}`);
    if (cached) {
      return JSON.parse(cached);
    }

    // Cache miss - fetch from database
    const user = await db.users.findById(id);

    // Store in cache with TTL
    await redis.setex(`user:${id}`, 3600, JSON.stringify(user));

    return user;
  }

  async updateUser(id: string, data: Partial<User>): Promise<User> {
    const user = await db.users.update(id, data);

    // Invalidate cache
    await redis.del(`user:${id}`);

    return user;
  }
}
```

## Write-Through Cache

Write to cache and database simultaneously:

```typescript
class ProductService {
  async updateProduct(id: string, data: Partial<Product>): Promise<Product> {
    // Update database
    const product = await db.products.update(id, data);

    // Update cache immediately
    await redis.setex(`product:${id}`, 3600, JSON.stringify(product));

    return product;
  }
}
```

## Write-Behind Cache

Write to cache immediately, database asynchronously:

```typescript
class AnalyticsService {
  async trackEvent(event: Event): Promise<void> {
    // Write to cache immediately
    await redis.lpush("events", JSON.stringify(event));

    // Process asynchronously
    this.processQueue();
  }

  private async processQueue() {
    const batch = await redis.lrange("events", 0, 99);
    if (batch.length === 0) return;

    // Batch write to database
    await db.events.insertMany(batch.map((e) => JSON.parse(e)));

    // Remove processed items
    await redis.ltrim("events", batch.length, -1);
  }
}
```

## Cache Invalidation Strategies

### Time-Based (TTL)

```typescript
// Simple TTL
await redis.setex("key", 300, "value"); // 5 minutes

// Refresh on access
async function getCachedValue(key: string): Promise<string | null> {
  const value = await redis.get(key);
  if (value) {
    // Refresh TTL on access
    await redis.expire(key, 300);
  }
  return value;
}
```

### Event-Based

```typescript
class OrderService {
  async createOrder(userId: string, items: OrderItem[]): Promise<Order> {
    const order = await db.orders.create({ userId, items });

    // Invalidate related caches
    await Promise.all([
      redis.del(`user:${userId}:orders`),
      redis.del(`user:${userId}:stats`),
      ...items.map((item) => redis.del(`product:${item.id}:stock`)),
    ]);

    return order;
  }
}
```

### Pattern-Based

```typescript
// Clear all user-related caches
async function clearUserCache(userId: string): Promise<void> {
  const keys = await redis.keys(`user:${userId}:*`);
  if (keys.length > 0) {
    await redis.del(...keys);
  }
}
```

## Multi-Level Caching

```typescript
class CacheManager {
  private l1Cache = new Map<string, any>(); // In-memory
  private l2Cache = redis; // Redis

  async get<T>(key: string): Promise<T | null> {
    // L1 cache (fastest)
    if (this.l1Cache.has(key)) {
      return this.l1Cache.get(key);
    }

    // L2 cache (fast)
    const value = await this.l2Cache.get(key);
    if (value) {
      const parsed = JSON.parse(value);
      this.l1Cache.set(key, parsed);
      return parsed;
    }

    // Cache miss
    return null;
  }

  async set(key: string, value: any, ttl: number): Promise<void> {
    this.l1Cache.set(key, value);
    await this.l2Cache.setex(key, ttl, JSON.stringify(value));
  }
}
```

## Cache Warming

Pre-populate cache with frequently accessed data:

```typescript
async function warmCache(): Promise<void> {
  // Popular products
  const popular = await db.products.find({ views: { $gt: 1000 } });

  for (const product of popular) {
    await redis.setex(`product:${product.id}`, 3600, JSON.stringify(product));
  }

  console.log(`Warmed cache with ${popular.length} products`);
}

// Run on application startup
warmCache();
```

## Cache Stampede Prevention

```typescript
async function getCachedOrCompute<T>(key: string, computeFn: () => Promise<T>, ttl: number): Promise<T> {
  const lockKey = `lock:${key}`;

  // Try to get from cache
  let value = await redis.get(key);
  if (value) return JSON.parse(value);

  // Try to acquire lock
  const acquired = await redis.set(lockKey, "1", "EX", 10, "NX");

  if (acquired) {
    try {
      // Compute value
      const computed = await computeFn();
      await redis.setex(key, ttl, JSON.stringify(computed));
      return computed;
    } finally {
      await redis.del(lockKey);
    }
  } else {
    // Wait and retry
    await new Promise((resolve) => setTimeout(resolve, 100));
    return getCachedOrCompute(key, computeFn, ttl);
  }
}
```

## Best Practices

1. **Cache what's expensive** - Database queries, API calls
2. **Set appropriate TTLs** - Balance freshness vs performance
3. **Monitor hit rates** - Track cache effectiveness
4. **Handle cache failures gracefully** - App should work without cache
5. **Use cache keys wisely** - Clear, consistent naming
6. **Consider cache size** - Memory limits matter

Effective caching requires understanding your data access patterns and business requirements.
